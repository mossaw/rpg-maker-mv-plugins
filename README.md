---
mossawがAIと一緒に作ったツクールMV用のプラグイン集です。
---

### SimpleAutoNewLine.js (自動改行)

メッセージウィンドウで、指定した文字数を超えると自動で改行します。

* **特徴**: 「。」や「！」が行頭に来ないようにする**禁則処理**付き。
* **設定項目**: `MaxChars`（改行する文字数）、`KinsokuChars`（行頭禁則文字）

### CustomMenu.js (メニューカスタム)

メインメニューの項目（アイテム、スキル、装備、ステータス、オプション、セーブ、ロード、所持金）を個別に表示・非表示にできます。

* **特徴**: パーティー画像を非表示にすると、コマンドウィンドウを**画面中央**に寄せることができます。
* **コマンド**: 標準では存在しない「ロード」コマンドをメニューに追加可能です。

### TitleMenuCustom.js (タイトルカスタム)

タイトル画面のメニュー項目をシンプルにできます。

* **設定項目**: `ShowContinue`（コンティニューの有無）、`ShowOptions`（オプションの有無）

### GreetingPlugin.js (挨拶サンプル)

プラグインコマンドで、今の時間帯設定に応じたメッセージを表示します。
サンプルスクリプトです。
* **コマンド**: `SayGreeting`
* **動作**: パラメータで「朝・昼・夜」を切り替えると、表示される挨拶が変わります。

---

# LlmConnector.js

本プラグインは、RPGツクールMVにおいてローカルLLM（llama.cpp等）と連携し、AIによる動的な台詞生成を可能にするプラグインです。
ゲーム内の状況やキャラクターの設定をAIに渡すことで、その場に応じた台詞をリアルタイムで生成します。

## 🖥 動作環境

本プラグインを動作させるためには、以下の環境が必要となります。

* **OS**: Windows 10 / 11 (64-bit)
* ※内部処理で `.exe` ファイルの実行および `taskkill` コマンドを使用しているため、Windows専用となります。


* **RPGツクールMV**: v1.6.1 以降（推奨）
* ※内部で `fetch` APIを使用しているため、比較的新しいバージョンのNW.js環境が必要です。


* **メモリ（RAM）**: 8GB以上（16GB以上を推奨）
* ※使用するモデルのサイズに依存しますが、ゲーム本体とLLMを同時に動かすため、余裕のあるメモリ容量が必要です。


* **CPU/GPU**: AVX2等の命令セットに対応したCPU、または性能の良いGPU。

## 🛠 事前準備

プラグインを導入する前に、以下のファイル配置を必ず行ってください。

1. プロジェクトのルートフォルダ（`index.html` がある場所）に `llm-bin` フォルダを作成し、その中に `llama-server.exe` 及びdll（全部）を配置してください。
2. 同じくルートフォルダに `models` フォルダを作成し、GGUF形式のモデルファイル（例：`gemma-3-4b-it-Q4_K_M.gguf`）を配置してください。

【llama】
https://github.com/ggml-org/llama.cpp/releases

【GGUF】
Gemma3で作りましたがほかのGGUFでも動くはず
https://ai.google.dev/gemma/docs/core?hl=ja


**フォルダ構成の例:**

```text
プロジェクトルート/
├── llm-bin/
│   └── llama-server.exe
├── models/
│   └── (使用するモデルファイル).gguf
├── js/
│   └── plugins/
│       └── LlmConnector.js
└── index.html

```

## 🚀 導入方法

1. `js/plugins` フォルダに `LlmConnector.js` をコピーします。
2. ツクールのプラグインマネージャーから `LlmConnector` を有効にします。
3. 以下のパラメータを適切に設定してください：
* **ポート番号**: `llama-server` が使用するポート（デフォルト: 8080）。
* **モデルファイル名**: `models` フォルダに配置したファイル名。
* **システムプロンプト**: AIへのキャラクター付けや出力制限の指示。



## 💬 使い方（プラグインコマンド）

イベントコマンドの「プラグインコマンド」から、以下の形式で実行してください。

```text
LLM_CHAT [キャラ名] [状況] [変数ID]

```

* **キャラ名**: 台詞を生成させたいキャラクターの名称。
* **状況**: キャラクターが置かれている現在の状況説明。
* **変数ID**: 生成された台詞を格納するゲーム変数の番号。

### 実行例

```text
LLM_CHAT 騎士 宿屋で一晩過ごして体力が回復した 10

```

このコマンドを実行すると、指定された状況に合わせた台詞が生成され、変数10番に代入されます。その後、「文章の表示」で `\V[10]` を呼び出すことで、生成された台詞を表示できます。

## ⚠️ 注意事項

* **起動時の待機**: ゲーム起動時にバックグラウンドでサーバーを立ち上げるため、初回の生成が可能になるまで数秒から数十秒の時間を要する場合があります。
* **終了処理**: ゲームウィンドウを閉じると自動的にサーバープロセスも終了するように設計されていますが、強制終了した場合にはプロセスが残る可能性があります。結構メモリ食うので要ウォッチです。

---

## 📜 ライセンス

1. AIエンジン (llama-server.exe)
   - 著作権: Copyright (c) 2023-2025 Georgi Gerganov and contributors
   - ライセンス: MIT License
   - リポジトリ: https://github.com/ggerganov/llama.cpp

2. AIモデル (gemma-3-4b-it-Q4_K_M.gguf)
   - 提供元: Google
   - ライセンス: Gemma Terms of Use
   - 規約詳細: https://ai.google.dev/gemma/terms
   - 本モデルは Google が提供する Gemma 3 を利用しています。
---